# Apache Spark & Hadoop

> Big Picture ‡∏ß‡πà‡∏≤‡∏™‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á

---

## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà Spark ‡πÅ‡∏•‡∏∞ Hadoop ‡πÅ‡∏Å‡πâ

‡∏•‡∏≠‡∏á‡∏ô‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ô‡∏µ‡πâ:

> ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Log ‡∏Ç‡∏ô‡∏≤‡∏î **10 TB** ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏ß‡πà‡∏≤ User ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô Login ‡∏Å‡∏µ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤

‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 TB ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ RAM (RAM ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 16-64 GB)
- ‡πÅ‡∏°‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å Disk ‡πÑ‡∏î‡πâ‡∏Å‡πá‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å
- ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:** ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (Distributed Computing)

```
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 TB
     ‚îÇ
     ‚îú‚îÄ‚îÄ‚ñ∫ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 1: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 2.5 TB
     ‚îú‚îÄ‚îÄ‚ñ∫ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 2: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 2.5 TB
     ‚îú‚îÄ‚îÄ‚ñ∫ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 3: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 2.5 TB
     ‚îî‚îÄ‚îÄ‚ñ∫ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà 4: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 2.5 TB
               ‚îÇ
               ‚ñº
         ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
```

‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á Hadoop ‡πÅ‡∏•‡∏∞ Spark

---

## Hadoop ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

![Hadoop](https://www.apache.org/logos/res/hadoop/default.png)
**Apache Hadoop** ‡∏Ñ‡∏∑‡∏≠ Framework ‡πÅ‡∏£‡∏Å ‡πÜ ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ Distributed Computing ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ 2 ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å:

### HDFS ‚Äî ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢

**HDFS (Hadoop Distributed File System)** ‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô **Block** (‡∏õ‡∏Å‡∏ï‡∏¥ 128MB) ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏™‡∏≥‡∏£‡∏≠‡∏á (Replication) ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢

```
‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î 512 MB
     ‚îÇ
     ‚îú‚îÄ‚îÄ Block 1 (128MB) ‚Üí Node A, Node B (‡∏™‡∏≥‡∏£‡∏≠‡∏á)
     ‚îú‚îÄ‚îÄ Block 2 (128MB) ‚Üí Node B, Node C (‡∏™‡∏≥‡∏£‡∏≠‡∏á)
     ‚îú‚îÄ‚îÄ Block 3 (128MB) ‚Üí Node C, Node A (‡∏™‡∏≥‡∏£‡∏≠‡∏á)
     ‚îî‚îÄ‚îÄ Block 4 (128MB) ‚Üí Node A, Node D (‡∏™‡∏≥‡∏£‡∏≠‡∏á)
```

### MapReduce ‚Äî ‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö Hadoop

MapReduce ‡∏Ñ‡∏∑‡∏≠ Programming Model ‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô 2 Phase:
- **Map:** ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ Record ‚Üí Key-Value pairs
- **Reduce:** ‡∏£‡∏ß‡∏° Value ‡∏ó‡∏µ‡πà‡∏°‡∏µ Key ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á MapReduce:** ‡∏ó‡∏∏‡∏Å Step ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô-‡∏≠‡πà‡∏≤‡∏ô Disk ‚Üí ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ Step

---

## Apache Spark ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
![ApacheSpark](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/3840px-Apache_Spark_logo.svg.png)
**Apache Spark** ‡∏Ñ‡∏∑‡∏≠ Distributed Computing Engine ‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡∏≠‡∏á MapReduce ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ô **RAM (In-Memory)** ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ MapReduce ‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 100 ‡πÄ‡∏ó‡πà‡∏≤‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏Å‡∏£‡∏ì‡∏µ

### Spark ‡∏Å‡∏±‡∏ö Hadoop ‚Äî ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

| | Hadoop MapReduce | Apache Spark |
|--|-----------------|--------------|
| **‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Step** | Disk | RAM (In-Memory) |
| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß** | ‡∏ä‡πâ‡∏≤ (Disk I/O ‡∏°‡∏≤‡∏Å) | ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏°‡∏≤‡∏Å |
| **API** | Low-level, ‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô | High-level (DataFrame, SQL) |
| **Streaming** | ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (Structured Streaming) |
| **ML** | ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô | ‡∏°‡∏µ MLlib ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß |

> **Spark ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà Hadoop ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î** ‚Äî Spark ‡∏°‡∏±‡∏Å‡∏£‡∏±‡∏ô‡∏ö‡∏ô HDFS ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ô Memory ‡πÅ‡∏ó‡∏ô

---

## ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Spark

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             Driver Program              ‚îÇ
‚îÇ  (‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Scala/Python ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô)    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  SparkContext / SparkSession            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Cluster Manager              ‚îÇ
‚îÇ  (Kubernetes / YARN / Standalone)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ              ‚îÇ
       ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Executor ‚îÇ    ‚îÇ Executor ‚îÇ  ... (‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß)
‚îÇ  Node 1  ‚îÇ    ‚îÇ  Node 2  ‚îÇ
‚îÇ Task Task‚îÇ    ‚îÇ Task Task‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

- **Driver:** ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‚Äî ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£
- **Executor:** Worker ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‚Äî ‡∏£‡∏±‡∏ö Task ‡∏à‡∏≤‡∏Å Driver ‡∏°‡∏≤‡∏£‡∏±‡∏ô
- **Task:** ‡∏á‡∏≤‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å ‡πÜ ‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡∏à‡∏≤‡∏Å Operation ‡πÉ‡∏´‡∏ç‡πà

---

## Spark ‡∏ö‡∏ô Kubernetes

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô Spark ‡∏ö‡∏ô Kubernetes ‡∏ú‡πà‡∏≤‡∏ô Spark Operator:

```
SparkApplication (YAML)
        ‚îÇ
        ‚ñº
  Spark Operator
        ‚îÇ
        ‚îú‚îÄ‚îÄ‚ñ∫ Spark Driver Pod   (‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Driver ‡∏£‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)
        ‚îÇ
        ‚îî‚îÄ‚îÄ‚ñ∫ Spark Executor Pods (Worker ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß)
```

‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ö‡∏ô Kubernetes:
- ‡πÉ‡∏ä‡πâ Infrastructure ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Service ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
- Scale Executor ‡∏Ç‡∏∂‡πâ‡∏ô-‡∏•‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Resource ‡∏î‡πâ‡∏ß‡∏¢ Kubernetes Resource Limits

---

## Lazy Evaluation ‚Äî ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á Spark

Spark ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô Operation ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠ **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏£‡∏¥‡∏á** (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Action)

```
val df = spark.read.csv("data.csv")   // ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
  .filter(col("age") > 18)            // ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà Filter
  .groupBy("city")                    // ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà Group
  .count()                            // ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ô‡∏±‡∏ö

df.show()  // ‚Üê ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡∏∞‡∏ó‡∏µ‡πà Spark ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á!
```

‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Lazy Evaluation: Spark ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ **‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô Optimize** ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î

---
# DataFrame

> ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ ‚Äî ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Spark SQL API

---

## DataFrame ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

‡∏•‡∏≠‡∏á‡∏ô‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á **‡∏ï‡∏≤‡∏£‡∏≤‡∏á Excel** ‡∏ó‡∏µ‡πà:
- ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠ Column ‡πÅ‡∏•‡∏∞ Type ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (Schema)
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏±‡∏ô ‡∏•‡πâ‡∏≤‡∏ô ‡πÅ‡∏ñ‡∏ß ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ Code

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   name   ‚îÇ age ‚îÇ  city  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Alice   ‚îÇ  28 ‚îÇBangkok ‚îÇ  ‚Üê ‡∏≠‡∏¢‡∏π‡πà Node 1
‚îÇ  Bob     ‚îÇ  35 ‚îÇChiang  ‚îÇ  ‚Üê ‡∏≠‡∏¢‡∏π‡πà Node 1
‚îÇ  Charlie ‚îÇ  22 ‚îÇPhuket  ‚îÇ  ‚Üê ‡∏≠‡∏¢‡∏π‡πà Node 2
‚îÇ  Diana   ‚îÇ  41 ‚îÇBangkok ‚îÇ  ‚Üê ‡∏≠‡∏¢‡∏π‡πà Node 2
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       Spark DataFrame
```

**‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÉ‡∏ô Code ‡πÄ‡∏£‡∏≤‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà Spark ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ

---

## DataFrame vs RDD

Spark ‡∏°‡∏µ 2 abstraction ‡∏´‡∏•‡∏±‡∏Å:

| | RDD | DataFrame |
|--|-----|-----------|
| **‡∏£‡∏∞‡∏î‡∏±‡∏ö** | Low-level | High-level |
| **Type Safety** | ‚úÖ (Compile-time) | ‚ö†Ô∏è (Runtime) |
| **Optimization** | ‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏≠‡∏á | ‚úÖ Catalyst Optimizer ‡∏ä‡πà‡∏ß‡∏¢ |
| **‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢** | ‚ùå Verbose | ‚úÖ ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ SQL |
| **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö** | ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Low-level | ‡∏á‡∏≤‡∏ô ETL ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ |

> **Dataset[T]** ‡∏Ñ‡∏∑‡∏≠ hybrid ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á ‚Äî ‡∏°‡∏µ Schema ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô DataFrame ‡πÅ‡∏ï‡πà Type-safe ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô RDD ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Scala ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å

---

## SparkSession ‚Äî ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á

```scala
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder()
  .appName("MySparkJob")
  .master("local[*]")   // ‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å CPU Core)
  .getOrCreate()

import spark.implicits._  // ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ .toDF() ‡πÅ‡∏•‡∏∞ $ syntax ‡πÑ‡∏î‡πâ
```

---

## ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame

### ‡∏à‡∏≤‡∏Å Collection (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Test)

```scala
val data = Seq(
  ("Alice",   28, "Bangkok"),
  ("Bob",     35, "Chiang Mai"),
  ("Charlie", 22, "Phuket"),
  ("Diana",   41, "Bangkok")
)

val df = data.toDF("name", "age", "city")

df.printSchema()
// root
//  |-- name: string (nullable = true)
//  |-- age: integer (nullable = false)
//  |-- city: string (nullable = true)
```

### ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV

```scala
val df = spark.read
  .option("header", "true")      // ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô Header
  .option("inferSchema", "true") // ‡πÉ‡∏´‡πâ Spark ‡πÄ‡∏î‡∏≤ Type ‡πÄ‡∏≠‡∏á
  .csv("data/users.csv")
```

### ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Parquet (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production)

```scala
val df = spark.read.parquet("data/users.parquet")
```

> **Parquet** ‡∏Ñ‡∏∑‡∏≠ Columnar Format ‚Äî ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ CSV ‡∏°‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Ñ‡πà‡∏ö‡∏≤‡∏á Column

---

## Transformation ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

Transformation ‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏Ñ‡∏∑‡∏≠ **Lazy** (‡∏î‡∏π‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ô spark-hadoop.md)

### filter / where

```scala
// ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏¢‡∏∏ > 25
val adults = df.filter(col("age") > 25)

// ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö SQL-like ‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
val adults = df.where("age > 25")
```

### select ‡πÅ‡∏•‡∏∞ withColumn

```scala
import org.apache.spark.sql.functions._

// ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà‡∏ö‡∏≤‡∏á Column
val names = df.select("name", "city")

// ‡πÄ‡∏û‡∏¥‡πà‡∏° Column ‡πÉ‡∏´‡∏°‡πà
val withFullInfo = df.withColumn(
  "is_adult",
  col("age") >= 18
)

// ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Column ‡πÉ‡∏´‡∏°‡πà
val withLabel = df.withColumn(
  "age_group",
  when(col("age") < 30, "young")
    .when(col("age") < 50, "middle")
    .otherwise("senior")
)
```

### groupBy ‡πÅ‡∏•‡∏∞ Aggregation

```scala
// ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡∏≠‡∏á
val byCity = df
  .groupBy("city")
  .agg(
    count("*").as("total"),
    avg("age").as("avg_age"),
    max("age").as("max_age")
  )

byCity.show()
// +----------+-----+-------+-------+
// |      city|total|avg_age|max_age|
// +----------+-----+-------+-------+
// |   Bangkok|    2|   34.5|     41|
// |Chiang Mai|    1|   35.0|     35|
// |    Phuket|    1|   22.0|     22|
// +----------+-----+-------+-------+
```

### join

```scala
val orders = spark.read.parquet("data/orders.parquet")

// Inner Join
val result = df.join(orders, df("name") === orders("user_name"))

// Left Join
val result = df.join(orders, df("name") === orders("user_name"), "left")
```

---

## Action ‚Äî ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ Spark ‡∏£‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á

```scala
// ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (default 20 ‡πÅ‡∏ñ‡∏ß)
df.show()
df.show(50)        // ‡πÅ‡∏™‡∏î‡∏á 50 ‡πÅ‡∏ñ‡∏ß
df.show(false)     // ‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß

// ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Memory (‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å)
val rows: Array[Row] = df.collect()

// ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß
val count: Long = df.count()

// ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ (‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á write ‡πÄ‡∏õ‡πá‡∏ô Action)
df.write
  .mode("overwrite")
  .parquet("output/result.parquet")
```

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Pipeline ‡∏à‡∏£‡∏¥‡∏á

```scala
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object UserAnalysis {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("UserAnalysis")
      .getOrCreate()

    import spark.implicits._

    // 1. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    val users = spark.read
      .option("header", "true")
      .option("inferSchema", "true")
      .csv("data/users.csv")

    // 2. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
    val cleaned = users
      .filter(col("age").isNotNull)
      .filter(col("age") > 0 && col("age") < 120)
      .withColumn("city", trim(lower(col("city"))))

    // 3. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    val summary = cleaned
      .groupBy("city")
      .agg(
        count("*").as("user_count"),
        round(avg("age"), 1).as("avg_age")
      )
      .orderBy(desc("user_count"))

    // 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    summary.write
      .mode("overwrite")
      .parquet("output/city_summary")

    spark.stop()
  }
}
```
# Cats Effect

> IO Monad, Fiber, ‡πÅ‡∏•‡∏∞ Resource Management ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Functional Programming ‡πÉ‡∏ô Scala

---

## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà Cats Effect ‡πÅ‡∏Å‡πâ

‡πÉ‡∏ô FP ‡∏ö‡∏£‡∏¥‡∏™‡∏∏‡∏ó‡∏ò‡∏¥‡πå (Pure FP) ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô **Pure** ‚Äî ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Å‡∏µ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ú‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏µ Side Effect

‡πÅ‡∏ï‡πà‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ:
- ‡∏≠‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå
- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Network
- ‡∏≠‡πà‡∏≤‡∏ô System Clock
- Print ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

‡∏™‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏•‡πâ‡∏ß‡∏ô‡πÄ‡∏õ‡πá‡∏ô **Side Effect** ‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô

**‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:** ‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Pure FP ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏ó‡∏≥ Side Effect ‡πÑ‡∏î‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:** ‡∏´‡πà‡∏≠ Side Effect ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô **IO** ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

---

## IO Monad ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

`IO[A]` ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‚Äî ‡∏°‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ **‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢** ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£

‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **‡πÉ‡∏ö‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£** ‡∏Å‡∏±‡∏ö **‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á**:

```
val recipe: IO[Cake] = IO {
  mixIngredients()
  bakeInOven()
  Cake()
}
// ‡∏ì ‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢
// recipe ‡πÅ‡∏Ñ‡πà "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢" ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£

recipe.unsafeRunSync()
// ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡∏∞‡∏ó‡∏µ‡πà "‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á"
```

---

## IO ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

```scala
import cats.effect.IO

// ‡∏™‡∏£‡πâ‡∏≤‡∏á IO ‡∏à‡∏≤‡∏Å Side Effect
val printHello: IO[Unit] = IO.println("Hello, World!")

// ‡∏™‡∏£‡πâ‡∏≤‡∏á IO ‡∏ó‡∏µ‡πà return ‡∏Ñ‡πà‡∏≤
val readLine: IO[String] = IO.readLine

// IO ‡∏ó‡∏µ‡πà return ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ Side Effect ‡∏à‡∏£‡∏¥‡∏á)
val pure: IO[Int] = IO.pure(42)

// IO ‡∏ó‡∏µ‡πà Delay ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô (Lazy)
val delayed: IO[Long] = IO(System.currentTimeMillis())
```

### ‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠ IO ‡∏î‡πâ‡∏ß‡∏¢ flatMap ‡πÅ‡∏•‡∏∞ for-comprehension

```scala
// ‡πÅ‡∏ö‡∏ö flatMap
val program: IO[Unit] =
  IO.println("What's your name?")
    .flatMap(_ => IO.readLine)
    .flatMap(name => IO.println(s"Hello, $name!"))

// ‡πÅ‡∏ö‡∏ö for-comprehension (‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤)
val program: IO[Unit] = for {
  _    <- IO.println("What's your name?")
  name <- IO.readLine
  _    <- IO.println(s"Hello, $name!")
} yield ()
```

---

## IOApp ‚Äî Entry Point

‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Cats Effect ‡∏ï‡πâ‡∏≠‡∏á Extend `IOApp` ‡πÅ‡∏ó‡∏ô `App` ‡∏õ‡∏Å‡∏ï‡∏¥

```scala
import cats.effect.{IO, IOApp}

object Main extends IOApp.Simple {
  def run: IO[Unit] = for {
    _    <- IO.println("Enter your name:")
    name <- IO.readLine
    _    <- IO.println(s"Hello, $name!")
  } yield ()
}
```

`IOApp` ‡∏à‡∏∞‡∏£‡∏±‡∏ô `run` ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Runtime (Thread Pool, Signal Handling) ‡πÉ‡∏´‡πâ

---

## Error Handling ‡πÉ‡∏ô IO

```scala
import cats.effect.IO

// handleError ‚Äî ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Error ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ Default Value
val safe: IO[String] =
  IO(riskyOperation())
    .handleError(err => s"Error: ${err.getMessage}")

// attempt ‚Äî ‡πÅ‡∏õ‡∏•‡∏á IO[A] ‡πÄ‡∏õ‡πá‡∏ô IO[Either[Throwable, A]]
val result: IO[Either[Throwable, String]] =
  IO(riskyOperation()).attempt

// ‡πÉ‡∏ä‡πâ result
val program: IO[Unit] = result.flatMap {
  case Right(value) => IO.println(s"Success: $value")
  case Left(error)  => IO.println(s"Failed: ${error.getMessage}")
}
```

---

## Fiber ‚Äî Concurrent Tasks

**Fiber** ‡∏Ñ‡∏∑‡∏≠ "Thread ‡πÄ‡∏ö‡∏≤" ‡∏ó‡∏µ‡πà Cats Effect ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏á ‚Äî ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏•‡πâ‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Å‡∏¥‡∏ô RAM ‡∏°‡∏≤‡∏Å

‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡πÉ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á** ‚Äî ‡πÄ‡∏£‡∏≤‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏≠‡∏≤‡∏ú‡∏•‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á

```scala
import cats.effect.{IO, IOApp}
import scala.concurrent.duration._

object FiberExample extends IOApp.Simple {
  def fetchData(id: Int): IO[String] =
    IO.sleep(1.second) *> IO.pure(s"Data-$id")

  def run: IO[Unit] = for {
    // Start ‡∏™‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏Å‡∏±‡∏ô)
    fiber1 <- fetchData(1).start
    fiber2 <- fetchData(2).start

    // ‡∏£‡∏≠‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà
    result1 <- fiber1.join
    result2 <- fiber2.join

    _ <- IO.println(s"Got: $result1, $result2")
  } yield ()
}
// ‡∏£‡∏±‡∏ô‡πÅ‡∏Ñ‡πà ~1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
```

### parMapN ‚Äî ‡∏£‡∏±‡∏ô IO ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏Å‡∏ß‡πà‡∏≤)

```scala
import cats.syntax.parallel._

val program: IO[Unit] = (
  fetchData(1),
  fetchData(2),
  fetchData(3)
).parMapN { (r1, r2, r3) =>
  println(s"Results: $r1, $r2, $r3")
}
```

---

## Resource ‚Äî ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Resource ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏¥‡∏î

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏¥‡∏Å: ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå/Connection ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏∑‡∏°‡∏õ‡∏¥‡∏î

```scala
// ‚ùå ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢ ‚Äî ‡∏ñ‡πâ‡∏≤ use() throw Exception ‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ close()
val conn = openConnection()
conn.use()
conn.close()  // ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å!
```

`Resource` ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ Guarantee ‡∏ß‡πà‡∏≤ finalizer ‡∏à‡∏∞‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏°‡∏≠ ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î Error ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

```scala
import cats.effect.{IO, Resource}

// ‡∏™‡∏£‡πâ‡∏≤‡∏á Resource
def dbConnection(url: String): Resource[IO, Connection] =
  Resource.make(
    IO(openConnection(url))   // Acquire: ‡πÄ‡∏õ‡∏¥‡∏î Connection
  )(conn =>
    IO(conn.close())          // Release: ‡∏õ‡∏¥‡∏î Connection (‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏°‡∏≠)
  )

// ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
val program: IO[Unit] =
  dbConnection("jdbc:postgresql://localhost/mydb").use { conn =>
    IO(conn.query("SELECT * FROM users"))
      .flatMap(rows => IO.println(s"Got ${rows.size} rows"))
  }
// conn.close() ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á use block ‡∏à‡∏ö
// ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞ Success ‡∏´‡∏£‡∏∑‡∏≠ Exception
```

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏°

```scala
import cats.effect.{IO, IOApp, Resource}
import cats.syntax.parallel._
import scala.concurrent.duration._

object DataPipeline extends IOApp.Simple {

  // ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Source ‡∏ï‡πà‡∏≤‡∏á ‡πÜ
  def fetchFromSource(source: String): IO[List[String]] =
    IO.sleep(500.millis) *>
    IO.pure(List(s"$source-record-1", s"$source-record-2"))

  // ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Source
  def fetchAll: IO[List[String]] = (
    fetchFromSource("db"),
    fetchFromSource("api"),
    fetchFromSource("file")
  ).parMapN { (db, api, file) =>
    db ++ api ++ file
  }

  def run: IO[Unit] = for {
    _       <- IO.println("Starting pipeline...")
    records <- fetchAll
    _       <- IO.println(s"Fetched ${records.size} records")
    _       <- records.traverse_(r => IO.println(s"  - $r"))
    _       <- IO.println("Done!")
  } yield ()
}
```

---
## ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
- [Cats Effect Docs](https://typelevel.org/cats-effect/)
- [Cats Effect Tutorial](https://typelevel.org/cats-effect/docs/tutorial)

# Type-level Programming

> Typeclass ‡πÅ‡∏•‡∏∞ `implicit` ‚Äî Polymorphism ‡πÅ‡∏ö‡∏ö Functional Programming
>
> ‚öôÔ∏è **Code ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Scala 2.13** (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Apache Spark)  
> ‡∏°‡∏µ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ Scala 3 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á Section

---

## ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà Type-level ‡πÅ‡∏Å‡πâ

‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô `sum` ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á `List[Int]`, `List[Double]`, ‡πÅ‡∏•‡∏∞ Type ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ:

```scala
// ‡πÅ‡∏ö‡∏ö OOP ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Äî Overload ‡∏ó‡∏µ‡∏•‡∏∞ Type
def sum(xs: List[Int]): Int       = xs.reduce(_ + _)
def sum(xs: List[Double]): Double = xs.reduce(_ + _)
def sum(xs: List[Long]): Long     = xs.reduce(_ + _)
// ‡πÄ‡∏û‡∏¥‡πà‡∏° Type ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á = ‡πÅ‡∏Å‡πâ Code ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
// ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ñ‡πâ‡∏≤ Class ‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å Library ‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô
```

**Type-level ‡∏î‡πâ‡∏ß‡∏¢ Typeclass** ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡πÅ‡∏¢‡∏Å **"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ"** ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å **"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"**

```
"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ" (Typeclass)    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" (Type)
     Summable        +          Int
     Summable        +          Double
     Summable        +          BigDecimal   ‚Üê ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ sum
```

---

## Typeclass ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**Typeclass** ‡∏Ñ‡∏∑‡∏≠ `trait` ‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ Type ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏∞‡πÑ‡∏£ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ Class ‡πÄ‡∏î‡∏¥‡∏°

‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á** ‚Äî ‡∏ñ‡πâ‡∏≤ Type `A` ‡∏°‡∏µ‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á `Summable` ‚Üí ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö `sum` ‡πÑ‡∏î‡πâ

---

## ‡∏™‡∏£‡πâ‡∏≤‡∏á Typeclass ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (Scala 2.13)

### Step 1: ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® Typeclass ‡πÄ‡∏õ‡πá‡∏ô `trait`

```scala
// Typeclass = trait ‡∏ó‡∏µ‡πà‡∏°‡∏µ Type Parameter
trait Summable[A] {
  def empty: A
  def add(x: A, y: A): A
}
```

---

### Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Instance ‡∏î‡πâ‡∏ß‡∏¢ `implicit val`

```scala
// Instance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Int
implicit val intSummable: Summable[Int] = new Summable[Int] {
  def empty: Int               = 0
  def add(x: Int, y: Int): Int = x + y
}

// Instance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Double
implicit val doubleSummable: Summable[Double] = new Summable[Double] {
  def empty: Double                    = 0.0
  def add(x: Double, y: Double): Double = x + y
}

// Instance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö String
implicit val stringSummable: Summable[String] = new Summable[String] {
  def empty: String                    = ""
  def add(x: String, y: String): String = x + y
}
```

> **‡πÉ‡∏™‡πà Instance ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô?**  
> Scala 2.13 ‡∏°‡∏µ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Instance 2 ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏Å:
> 1. **Companion Object ‡∏Ç‡∏≠‡∏á Typeclass** (`object Summable { implicit val ... }`)
> 2. **Scope ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô** ‡∏´‡∏£‡∏∑‡∏≠ Import ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
>
> ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÉ‡∏ô Companion Object ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Import ‡∏û‡∏¥‡πÄ‡∏®‡∏©

---

### Step 3: ‡∏£‡∏±‡∏ö Instance ‡∏î‡πâ‡∏ß‡∏¢ `implicit` parameter

```scala
def sum[A](xs: List[A])(implicit s: Summable[A]): A =
  xs.foldLeft(s.empty)(s.add)

// ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‚Äî Compiler ‡∏´‡∏≤ Instance ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
sum(List(1, 2, 3))                // ‚Üí 6
sum(List(1.5, 2.5, 3.0))          // ‚Üí 7.0
sum(List("Hello", " ", "World"))  // ‚Üí "Hello World"
```

#### ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö Context Bound ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤

```scala
// [A: Summable] ‡∏Ñ‡∏∑‡∏≠ Syntactic Sugar ‡∏Ç‡∏≠‡∏á (implicit s: Summable[A])
def sum[A: Summable](xs: List[A]): A = {
  val s = implicitly[Summable[A]] // ‡∏î‡∏∂‡∏á Instance ‡∏ó‡∏µ‡πà Compiler ‡∏´‡∏≤‡∏°‡∏≤‡πÉ‡∏´‡πâ
  xs.foldLeft(s.empty)(s.add)
}
```

---

> **üí° Scala 3 ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö**
>
> Scala 3 ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Syntax ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô ‡πÅ‡∏ï‡πà‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á:
>
> | | Scala 2.13 | Scala 3 |
> |--|-----------|---------|
> | ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® Instance | `implicit val x: T = ...` | `given x: T = ...` |
> | ‡∏£‡∏±‡∏ö Instance | `(implicit x: T)` | `(using x: T)` |
> | Context Bound | `[A: TC]` + `implicitly[TC[A]]` | `[A: TC]` + `summon[TC[A]]` |
> | Import | `import pkg._` | `import pkg.given` |
>
> ```scala
> // Scala 3
> given intSummable: Summable[Int] with {
>   def empty = 0
>   def add(x: Int, y: Int) = x + y
> }
> def sum[A](xs: List[A])(using s: Summable[A]): A = ...
> ```

---

## Implicit Class ‚Äî ‡πÄ‡∏û‡∏¥‡πà‡∏° Method ‡πÉ‡∏´‡πâ Type ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÅ‡∏Å‡πâ Class ‡πÄ‡∏î‡∏¥‡∏°

‡πÉ‡∏ô Scala 2.13 ‡πÉ‡∏ä‡πâ **Implicit Class** (Scala 3 ‡πÉ‡∏ä‡πâ `extension`)

```scala
// ‡πÄ‡∏û‡∏¥‡πà‡∏° Method .doubled ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å Type ‡∏ó‡∏µ‡πà‡∏°‡∏µ Summable
implicit class SummableOps[A](val x: A)(implicit s: Summable[A]) {
  def doubled: A = s.add(x, x)
}

5.doubled          // 10
3.14.doubled       // 6.28
"Hello".doubled    // "HelloHello"
```

Pattern ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Cats ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ **Syntax** ‚Äî ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Method ‡πÅ‡∏ö‡∏ö `x.show`, `x === y` ‡πÑ‡∏î‡πâ

---

## Typeclass ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô Cats (Scala 2.13)

### Eq ‚Äî ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡πÅ‡∏ö‡∏ö Type-safe

```scala
import cats.Eq
import cats.syntax.eq._

case class User(id: Int, name: String)

implicit val userEq: Eq[User] = Eq.by(_.id)

val u1 = User(1, "Alice")
val u2 = User(1, "Alice (copy)")
val u3 = User(2, "Bob")

u1 === u2  // true  (id ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)
u1 === u3  // false
u1 =!= u3  // true

// ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å == ‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà Compiler ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Eq[User]
// ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí Compile Error ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ Runtime Error
```

---

### Show ‚Äî ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô String ‡πÅ‡∏ö‡∏ö Type-safe

```scala
import cats.Show
import cats.syntax.show._

case class User(id: Int, name: String)

implicit val showUser: Show[User] =
  Show.show(u => s"User(${u.id}, ${u.name})")

val user = User(42, "Alice")
user.show  // "User(42, Alice)"
// ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà .toString ‡∏ã‡∏∂‡πà‡∏á Compiler ‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£
```

---

### Functor ‚Äî map ‡∏ö‡∏ô Context ‡πÉ‡∏î ‡πÜ

`Functor[F[_]]` ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ `F` ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ `map` ‚Äî ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö `List`, `Option`, `IO` ‡∏Ø‡∏•‡∏Ø

```scala
import cats.Functor
import cats.syntax.functor._

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö F ‡πÉ‡∏î ‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ Functor ‚Äî ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á hardcode List ‡∏´‡∏£‡∏∑‡∏≠ Option
def doubleAll[F[_]: Functor](fa: F[Int]): F[Int] =
  fa.map(_ * 2)

doubleAll(List(1, 2, 3))       // List(2, 4, 6)
doubleAll(Option(5))           // Some(10)
doubleAll(Option.empty[Int])   // None
```

---

### Monad ‚Äî flatMap ‡∏ö‡∏ô Context ‡πÉ‡∏î ‡πÜ

```scala
import cats.Monad
import cats.syntax.flatMap._
import cats.syntax.functor._

def pipeline[F[_]: Monad](input: F[Int]): F[String] = for {
  n      <- input
  doubled = n * 2
  result <- Monad[F].pure(s"Result: $doubled")
} yield result

pipeline(Option(5))          // Some("Result: 10")
pipeline(Option.empty[Int])  // None
pipeline(List(1, 2, 3))      // List("Result: 2", "Result: 4", "Result: 6")
// Code ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏Å‡πâ‡∏≠‡∏ô ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Type ‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢
```

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏° ‚Äî ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Spark Pipeline

```scala
import cats.Show
import cats.syntax.show._

case class SparkRecord(id: Long, value: Double, label: String)

// ‡πÉ‡∏™‡πà Instance ‡πÉ‡∏ô Companion Object ‚Üí ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Import ‡∏û‡∏¥‡πÄ‡∏®‡∏©
object SparkRecord {
  implicit val showRecord: Show[SparkRecord] =
    Show.show(r => s"[${r.id}] ${r.label}: ${r.value}")
}

// ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Generic ‚Äî ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Ñ‡πà Show ‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ß‡πà‡∏≤ Type ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
def logAll[A: Show](items: Seq[A]): Unit =
  items.foreach(item => println(item.show))

val records = Seq(
  SparkRecord(1, 42.5, "temperature"),
  SparkRecord(2, 98.6, "pressure"),
  SparkRecord(3, 15.0, "humidity")
)

logAll(records)
// [1] temperature: 42.5
// [2] pressure: 98.6
// [3] humidity: 15.0

// ‡πÄ‡∏û‡∏¥‡πà‡∏° Type ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï ‡πÅ‡∏Ñ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏° Show instance ‚Äî ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ logAll ‡πÄ‡∏•‡∏¢
```

---

## ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Scala 2.13)

```
trait Summable[A]            ‚Üê ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® "‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á" ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ
        ‚îÇ
implicit val/object          ‚Üê ‡∏≠‡∏≠‡∏Å "‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á" ‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Type
        ‚îÇ
(implicit ev: Summable[A])   ‚Üê ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á‡∏ô‡∏±‡πâ‡∏ô
  ‡∏´‡∏£‡∏∑‡∏≠ [A: Summable]          ‚Üê Syntax ‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤ (Context Bound)
        ‚îÇ
implicit class Ops[A]        ‚Üê ‡πÄ‡∏û‡∏¥‡πà‡∏° Method ‡πÄ‡∏Ç‡πâ‡∏≤ Type (Syntax Extension)
```

---

## ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [Cats Typeclasses](https://typelevel.org/cats/typeclasses.html)
- [Scala 2 Implicit Parameters](https://docs.scala-lang.org/tour/implicit-parameters.html)
- [Scala 3 Contextual Abstractions](https://docs.scala-lang.org/scala3/reference/contextual/) (‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ñ‡πâ‡∏≤‡∏™‡∏ô‡πÉ‡∏à Scala 3)

## JVM ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

‡∏•‡∏≠‡∏á‡∏ô‡∏∂‡∏Å‡∏ñ‡∏∂‡∏á **‡∏•‡πà‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤** ‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πà‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå

```
Source Code (.scala / .java / .kt)
          ‚îÇ
          ‚ñº  (Compiler ‡πÅ‡∏õ‡∏•)
      Bytecode (.class)
          ‚îÇ
          ‚ñº  (JVM ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô)
   ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á CPU ‡∏à‡∏£‡∏¥‡∏á ‡πÜ
```

**JVM (Java Virtual Machine)** ‡∏Ñ‡∏∑‡∏≠ Runtime ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô Bytecode ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ô Machine Code ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ô‡∏µ‡πâ:
- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å OS ‡∏ó‡∏µ‡πà‡∏°‡∏µ JVM ("Write Once, Run Anywhere")
- ‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà Compile ‡πÄ‡∏õ‡πá‡∏ô Bytecode ‡πÑ‡∏î‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‚Üí ‡πÉ‡∏ä‡πâ Library ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ

---

## ‡∏ó‡∏≥‡πÑ‡∏° Java, Scala, Kotlin ‡πÉ‡∏ä‡πâ Library ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ?

‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏±‡πâ‡∏á 3 ‡∏†‡∏≤‡∏©‡∏≤ **Compile ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô** ‡∏Ñ‡∏∑‡∏≠ JVM Bytecode

```
Java   ‚îÄ‚îÄ‚îê
Scala  ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ JVM Bytecode ‚îÄ‚îÄ‚ñ∫ JVM ‡∏£‡∏±‡∏ô
Kotlin ‚îÄ‚îÄ‚îò
```

‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤:
- Spark ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Scala ‚Üí ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Java ‡πÅ‡∏•‡∏∞ Kotlin
- Cats Effect ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Scala ‚Üí ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Library ‡∏Ç‡∏≠‡∏á Java ‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á ‡πÜ
- Library Java ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏°‡∏≤ 20 ‡∏õ‡∏µ ‚Üí Scala ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Wrap

---

## Maven Repository ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô **App Store ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Library** ‡∏Ç‡∏≠‡∏á‡πÇ‡∏•‡∏Å JVM

| ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö | JVM Ecosystem |
|-------------|--------------|
| npm (Node.js) | Maven Repository |
| package.json | `build.sbt` ‡∏´‡∏£‡∏∑‡∏≠ `pom.xml` |
| `npm install` | `sbt update` ‡∏´‡∏£‡∏∑‡∏≠ `mvn install` |
| node_modules/ | `~/.ivy2/` ‡∏´‡∏£‡∏∑‡∏≠ `~/.m2/` (Cache ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á) |

**Maven Central** ([mvnrepository.com](https://mvnrepository.com)) ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏•‡∏±‡∏á Public ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö Library ‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á JVM

---

## ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏∞‡∏ö‡∏∏ Dependency ‡πÉ‡∏ô sbt (Scala)

Library ‡πÉ‡∏ô JVM ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÅ‡∏ö‡∏ö **3 ‡∏™‡πà‡∏ß‡∏ô**:

```
GroupId : ArtifactId : Version
   ‚îÇ           ‚îÇ          ‚îÇ
   ‚îÇ           ‚îÇ          ‚îî‚îÄ‚îÄ ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
   ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‡∏ä‡∏∑‡πà‡∏≠ Library
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£/‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
```

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô `build.sbt`:

```scala
libraryDependencies ++= Seq(
  // Apache Spark
  "org.apache.spark" %% "spark-core" % "3.5.0",
  "org.apache.spark" %% "spark-sql"  % "3.5.0",

  // Cats Effect
  "org.typelevel" %% "cats-effect" % "3.5.4",

  // Cats Core
  "org.typelevel" %% "cats-core" % "2.10.0"
)
```

> **`%%` vs `%`**
> - `%%` = sbt ‡∏à‡∏∞‡πÄ‡∏ï‡∏¥‡∏° Scala version ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏ä‡πà‡∏ô `_2.13` ‡∏´‡∏£‡∏∑‡∏≠ `_3`)
> - `%` = ‡∏£‡∏∞‡∏ö‡∏∏ ArtifactId ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏≠‡∏á

---

## Scala Version ‡πÅ‡∏•‡∏∞ Binary Compatibility

Library ‡∏ó‡∏µ‡πà Compile ‡∏î‡πâ‡∏ß‡∏¢ Scala 2.13 **‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö** Scala 3 ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Bytecode ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏ß‡∏¥‡πà‡∏á‡∏ö‡∏ô JVM ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà Encoding ‡∏Ç‡∏≠‡∏á Scala-specific feature ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô

```
spark-core_2.13-3.5.0.jar  ‚Üê ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Scala 2.13
spark-core_3-3.5.0.jar     ‚Üê ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Scala 3
```

`%%` ‡πÉ‡∏ô sbt ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Suffix ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏° `scalaVersion` ‡πÉ‡∏ô `build.sbt`

---

## ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå Scala (sbt)

```
my-project/
‚îú‚îÄ‚îÄ build.sbt          ‚Üê ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Dependency, Scala Version
‚îú‚îÄ‚îÄ project/
‚îÇ   ‚îî‚îÄ‚îÄ build.properties  ‚Üê ‡∏Å‡∏≥‡∏´‡∏ô‡∏î sbt version
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ main/
    ‚îÇ   ‚îî‚îÄ‚îÄ scala/     ‚Üê Source Code ‡∏´‡∏•‡∏±‡∏Å
    ‚îî‚îÄ‚îÄ test/
        ‚îî‚îÄ‚îÄ scala/     ‚Üê Test Code
```

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á `build.sbt` ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:

```scala
ThisBuild / scalaVersion := "3.3.3"
ThisBuild / version      := "0.1.0"

lazy val root = (project in file("."))
  .settings(
    name := "my-spark-project",
    libraryDependencies ++= Seq(
      "org.apache.spark" %% "spark-sql" % "3.5.0"
    )
  )
```

---

## ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á sbt ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢

| ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ |
|--------|----------|
| `sbt compile` | Compile Source Code |
| `sbt run` | ‡∏£‡∏±‡∏ô Main Class |
| `sbt test` | ‡∏£‡∏±‡∏ô Test ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î |
| `sbt update` | Download Dependency ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ |
| `sbt package` | ‡∏™‡∏£‡πâ‡∏≤‡∏á JAR file |
| `sbt "runMain com.example.Main"` | ‡∏£‡∏±‡∏ô Class ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ |

- [sbt Reference Manual](https://www.scala-sbt.org/1.x/docs/)
- [Maven Repository](https://mvnrepository.com/)
