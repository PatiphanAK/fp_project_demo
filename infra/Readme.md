# YAML ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£

YAML ‡∏¢‡πà‡∏≠‡∏°‡∏≤‡∏à‡∏≤‡∏Å YAML Ain‚Äôt Markup Language
‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå Configuration ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ ‡∏Ñ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡∏£‡∏Å‡∏™‡∏≤‡∏¢‡∏ï‡∏≤

YAML ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ß‡πâ ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (data structure)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
```yaml
name: spark-job
version: 1.0
enabled: true
```
 
‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏¢ üëç ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡πÄ‡∏≠‡∏≤ **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Argo Workflow ‡πÅ‡∏ö‡∏ö Hello World**
‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ **‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏™‡πÄ‡∏õ‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö** ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î

---

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á YAML: Argo Workflow ‚Äì Hello World

‡πÑ‡∏ü‡∏•‡πå: `hello-workflow.yaml`

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: hello-world-
  namespace: argo

spec:
  entrypoint: hello
  templates:
    - name: hello
      container:
        image: alpine:3.18
        command: [echo]
        args: ["Hello Argo Workflows!"]
```

---

## ‡∏£‡∏±‡∏ô Workflow

```bash
kubectl apply -f hello-workflow.yaml
```

‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:

```bash
kubectl get workflows -n argo
```

‡∏î‡∏π log:

```bash
kubectl logs -n argo @latest
```

‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏î‡∏î‡∏π‡∏ú‡πà‡∏≤‡∏ô Argo UI ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢

---

# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ YAML ‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô

## 1. apiVersion / kind

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
```

‡∏ö‡∏≠‡∏Å Kubernetes ‡∏ß‡πà‡∏≤:

* resource ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á **Argo**
* ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏∑‡∏≠ **Workflow**

> ‡∏ñ‡πâ‡∏≤ Spark ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ `kind: SparkApplication`
> ‡∏ñ‡πâ‡∏≤ Pod ‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏∑‡∏≠ `kind: Pod`

---

## 2. metadata

```yaml
metadata:
  generateName: hello-world-
  namespace: argo
```

* `generateName`
  ‚Üí ‡πÉ‡∏´‡πâ Kubernetes ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÄ‡∏ä‡πà‡∏ô
  `hello-world-abcde`

* `namespace`
  ‚Üí Workflow ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô namespace `argo`

---

## 3. spec (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Workflow)

```yaml
spec:
  entrypoint: hello
```

* `entrypoint` ‡∏Ñ‡∏∑‡∏≠ **‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á Workflow**
* ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ template ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á

> ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô `main()` ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°

---

## 4. templates

```yaml
templates:
  - name: hello
```

* `templates` ‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∏‡∏î‡∏Ç‡∏≠‡∏á ‚Äú‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‚Äù
* ‡πÅ‡∏ï‡πà‡∏•‡∏∞ template = **1 step / 1 pod**

---

## 5. container (Step-as-a-Pod)

```yaml
container:
  image: alpine:3.18
  command: [echo]
  args: ["Hello Argo Workflows!"]
```

‡πÅ‡∏õ‡∏•‡∏ï‡∏£‡∏á‡∏ï‡∏±‡∏ß:

* ‡∏™‡∏£‡πâ‡∏≤‡∏á **Pod**
* ‡πÉ‡∏ä‡πâ image `alpine`
* ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:

```bash
echo "Hello Argo Workflows!"
```

> ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Pod ‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à ‚Üí step ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚Üí workflow ‡∏à‡∏ö

---

# ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á Architecture
```text
Argo Workflow
   |
   v
Template: hello
   |
   v
Pod (alpine)
   |
   v
echo "Hello Argo Workflows!"
```

-----
‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ `pipeline1.yaml` ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
```yaml
            hadoopConf:
              "fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
              "fs.s3a.endpoint": "s3.ap-southeast-1.amazonaws.com"
              "fs.s3a.path.style.access": "true"
              "fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
              "fs.s3a.access.key": "Not Secure"
              "fs.s3a.secret.key": "Note Secure"
```
‡πÅ‡∏ï‡πà‡∏ß‡πà‡∏≤‡πÉ‡∏ô `pipeline2.yaml` ‡∏à‡∏∞ secure ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á security practice ‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Variable ‡∏à‡∏≤‡∏Å Environment
```yaml

            hadoopConf:
              "fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
              "fs.s3a.endpoint": "s3.ap-southeast-1.amazonaws.com"
              "fs.s3a.path.style.access": "false"
              "fs.s3a.aws.credentials.provider": "com.amazonaws.auth.EnvironmentVariableCredentialsProvider"
```
‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢
```bash kubectl create secret generic aws-creds -n spark-apps \
  --from-literal=aws-access-key=‡πÉ‡∏™‡πà_Access_KeyID‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ \
  --from-literal=aws-secret-key=‡πÉ‡∏™‡πà_Secret_AccessKey‡∏¢‡∏≤‡∏ß‡πÜ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
``` 
‡∏ñ‡πâ‡∏≤ 
```bash
secret/aws-creds created
```
‡∏Ñ‡∏∑‡∏≠ Ok
